{
  "full_review": "**Summary:**\nThis paper investigates the underlying mechanisms of graph contrastive learning (GCL). It challenges the conventional wisdom inherited from visual contrastive learning (VCL) by demonstrating that positive pairs, negative pairs, and complex graph augmentations are not always necessary for GCL to achieve competitive performance. The authors attribute these findings to the intrinsic architectural biases of graph neural networks (GNNs), particularly the implicit regularization embedded in message-passing operators. They provide theoretical analyses and empirical evidence to support their claims, suggesting a rethinking of GCL design principles around architectural considerations.\n\n**Strengths:**\nThe paper's strengths lie in its identification of counter-intuitive phenomena in GCL, such as the effectiveness of positive-free and negative-free learning. The theoretical analysis connecting graph convolution and ContraNorm to alignment and uniformity objectives is novel and insightful. The empirical evaluation is extensive, covering multiple datasets and GCL methods. The paper challenges existing assumptions in the field and offers a new perspective on GCL design.\n\n**Weaknesses:**\nThe paper overstates the novelty of its findings, given the existing body of literature on GCL and GNN architectures. The characterization of 'conventional wisdom' in GCL lacks specific citations to support its claims. The paper does not adequately discuss the potential impact of the observed architectural biases on the generalizability of GCL models to different graph datasets and tasks. The paper inadequately addresses the computational complexity and scalability of the proposed approach, particularly in comparison to existing GCL methods. The experimental design and evaluation metrics exhibit several weaknesses that limit the robustness of the paper's claims.\n\n**Questions:**\n1. Can the authors provide more specific citations to support their claims about 'conventional wisdom' in GCL?\n2. How do the observed architectural biases affect the performance of GCL models on graphs with different structural properties (e.g., heterophily)?\n3. Can the authors provide a more detailed analysis of the computational complexity and scalability of their approach, including comparisons to existing GCL methods?\n4. What are the limitations of the theoretical framework and empirical validation, and how might these limitations affect the generalizability of the findings?\n5. How does the performance of the proposed approach vary with different GNN architectures and larger datasets?\n\n**Soundness:**\n3\n\n**Presentation:**\n3\n\n**Contribution:**\n3\n\n**Rating:**\n4\n\n**Confidence:**\n3",
  "feedback_comments": [
    "The paper claims to be the 'first' to provide a principled understanding of GCL, but this claim is not adequately supported due to the absence of any discussion regarding the limitations of the theoretical framework or empirical validation. The authors should provide a more balanced perspective by acknowledging the scope and constraints of their analysis.",
    "The paper overstates the novelty of its findings by not providing specific citations to support its characterization of 'conventional wisdom' in GCL. The authors need to substantiate their claims about existing beliefs and practices in the field with concrete references.",
    "The paper does not adequately discuss the potential impact of the observed architectural biases on the generalizability of GCL models to different graph datasets and tasks. While empirical evidence is presented across several datasets, the limited dataset characterization restricts the assessment of representativeness and generalizability. The authors should include a more comprehensive discussion of how the properties of different graph datasets might affect the performance and generalizability of GCL models.",
    "The paper lacks a comprehensive analysis of the computational cost and scalability of the proposed approach, especially concerning Gaussian noise augmentation. The authors should provide explicit information on computational efficiency and performance across different graph sizes and complexities, including a comparison of runtime and memory usage against existing GCL methods.",
    "The justification for the selection of baseline methods is limited, particularly beyond ContraNorm. It is unclear whether the chosen baselines are indeed the most relevant and state-of-the-art approaches. The authors should provide a more thorough justification for their choice of baselines and consider including additional relevant methods for comparison.",
    "The paper fails to discuss the statistical power of the Wilcoxon Signed Rank Test or validate its assumptions, weakening the validity of the statistical significance claims. The authors should provide a more detailed explanation of their statistical analysis, including a discussion of the power of the test and any assumptions that were made.",
    "The paper does not explicitly discuss limitations related to specific GNN architectures or the sensitivity of the results to the properties of the graph datasets used. The authors should acknowledge and address these limitations to provide a more balanced and nuanced perspective on their findings.",
    "The paper lacks a theoretical analysis of computational complexity, including time and space complexity in relation to graph size and feature dimensionality. The authors should include a theoretical analysis to provide a more complete understanding of the computational demands of their approach."
  ]
}