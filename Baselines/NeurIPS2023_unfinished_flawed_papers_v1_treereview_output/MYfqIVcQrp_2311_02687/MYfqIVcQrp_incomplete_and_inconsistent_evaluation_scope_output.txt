{
  "full_review": "**Summary:**\nThis paper investigates graph contrastive learning (GCL) and reveals properties that differ from visual contrastive learning (VCL). The authors demonstrate that positive samples are dispensable for competitive GCL, negative samples are irrelevant for graph-level tasks, and crude, domain-agnostic noise perturbations suffice for state-of-the-art performance. They attribute these findings to the architectural inductive bias of graph neural networks (GNNs), particularly the implicit regularization of graph convolution and the role of the projection head. The paper provides theoretical insights connecting graph convolution with a neighbor-induced alignment loss and ContraNorm with a neighbor-induced uniformity loss.\n\n**Strengths:**\nThe paper challenges common assumptions in GCL inherited from VCL, supported by extensive experiments. The theoretical analysis provides insights into the interplay between model architecture and contrastive objectives. The finding that GCL can work without positive samples, negative samples (for graph classification), and elaborate augmentations is intriguing and potentially impactful. The paper identifies and addresses the feature collapse issue in node classification by incorporating ContraNorm.\n\n**Weaknesses:**\nThe paper overstates the novelty of its findings, lacking sufficient discussion of prior work and limitations related to specific graph architectures or datasets. The justification for the choice of benchmarks is insufficient, raising concerns about the generalizability of the findings. The claims made in the abstract and introduction are not fully supported by the experimental results and theoretical analysis. The theoretical analysis lacks rigor and accessibility due to unclear assumptions, incomplete derivations, and insufficient empirical validation. The paper inadequately discusses potential limitations and edge cases, such as computational complexity and the impact of deviations from homophily.\n\n**Questions:**\n1.  Could the authors provide a more detailed discussion of prior work that has explored the dispensability of positive samples in contrastive learning, and clarify the specific novelties of this work in that context?\n2.  What are the computational costs associated with using domain-agnostic noise perturbations compared to task-specific data augmentations, and how does this affect the claim that noise perturbations are 'sufficient'?\n3.  Can the authors provide a more detailed justification for the choice of benchmarks used, and discuss any potential biases or limitations that might affect the generalizability of the findings?\n4.  Could the authors provide statistical significance values for the claim that negative samples are irrelevant for graph-level tasks, and discuss any potential confounding factors?\n5.  Could the authors clarify the assumptions underlying the theorems presented in the paper, and provide more detailed derivations to improve the rigor and accessibility of the theoretical analysis?\n6.  How does the performance of the proposed approach vary across different types of graph datasets, particularly those that deviate from the homophily assumption?\n7.  The paper mentions the hyperparameter $`\\alpha`$ as sensitive. Can the authors provide an explicit analysis of how different graph properties might influence the optimal hyperparameter settings?\n\n**Soundness:**\n3\n\n**Presentation:**\n3\n\n**Contribution:**\n3\n\n**Rating:**\n6\n\n**Confidence:**\n4",
  "feedback_comments": [
    "The paper claims positive samples are dispensable for competitive GCL, but the experimental results in Tables 2 and 3 show that the performance gap between 'Contrast' and 'NO Pos' varies across datasets and methods. A more detailed analysis of why this gap exists and under what conditions positive samples become more important is needed. The statistical significance of the differences should also be more thoroughly examined, as the reported p-values sometimes indicate insignificance even when there appears to be a performance difference.",
    "The paper states that negative samples are irrelevant for graph-level tasks, but the evidence in Table 3 shows that while 'NO Neg' sometimes outperforms 'Contrast', it also sometimes underperforms. A more nuanced discussion is needed to explain these variations and to identify potential confounding factors that might influence the relevance of negative samples in different graph classification scenarios. Furthermore, the statistical significance of these differences should be explicitly stated.",
    "The paper claims that crude, domain-agnostic noise perturbations are sufficient to unlock state-of-the-art performance, but this claim is not fully supported by the experimental results in Table 7. While Gaussian noise achieves comparable performance to domain-specific augmentations in some cases, it does not consistently outperform them across all datasets. A more detailed analysis of the trade-offs between domain-specific and domain-agnostic augmentations, including computational cost and efficiency, is needed to justify the claim of sufficiency.",
    "The theoretical analysis connecting graph convolution with a neighbor-induced alignment objective (Theorem 1) relies on the assumption that positive node pairs are drawn from a distribution defined by the normalized connection weight of the graph. The paper needs to provide a more detailed justification for this assumption and discuss its potential limitations, particularly in scenarios where the graph structure does not accurately reflect the underlying relationships between nodes.",
    "The paper introduces ContraNorm as a means of preventing feature collapse in the absence of negative samples for node classification, but the choice of the hyperparameter α in Equation 4 is not adequately addressed. The paper should provide a more detailed analysis of how different graph properties might influence the optimal hyperparameter settings and discuss the sensitivity of the results to variations in α.",
    "The paper's evaluation relies on a limited set of benchmark datasets. A more comprehensive evaluation, including a wider range of graph types and tasks, is needed to assess the generalizability of the findings. The paper should also explicitly state the criteria used for selecting the benchmarks and discuss any potential biases or limitations associated with their use.",
    "The paper claims that the projection head implicitly selects a low-rank subspace of features to satisfy the alignment loss in graph classification without negative samples. While the singular value distributions in Figure 1 provide some evidence for this claim, a more rigorous analysis is needed to quantify the rank reduction and to explain how this low-rank subspace contributes to downstream task performance.",
    "The paper lacks a thorough discussion of the computational complexity of the proposed approach, particularly the ContraNorm operation. An explicit analysis of the time and space complexity of ContraNorm, as well as a comparison to other normalization techniques, is needed to assess its practical applicability.",
    "The paper implicitly assumes homophily in its analysis of graph convolution and neighbor-induced alignment. A more explicit discussion of the potential impact of deviations from this assumption, particularly in heterophilic graphs, is needed to clarify the limitations of the theoretical results.",
    "The paper's presentation of the theoretical derivations is often too concise, making it difficult for readers to follow the reasoning. More detailed step-by-step derivations, along with clear explanations of the underlying assumptions and approximations, are needed to improve the accessibility and rigor of the theoretical analysis."
  ]
}