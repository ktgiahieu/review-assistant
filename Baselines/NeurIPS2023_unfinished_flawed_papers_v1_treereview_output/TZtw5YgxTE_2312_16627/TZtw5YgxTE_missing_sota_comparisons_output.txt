{
  "full_review": "**Summary:**\nThis paper introduces MIM4DD, a novel dataset distillation method that formulates the task as a mutual information maximization problem between real and synthetic datasets. The method derives a numerically feasible lower bound on the mutual information and maximizes it via contrastive learning. By pulling together positive pairs and pushing apart negatives in the contrastive space, the synthetic images inherit rich, label-aware structure. The authors demonstrate through experiments on MNIST and CIFAR10 that MIM4DD outperforms existing state-of-the-art methods and can be used as a plug-and-play module for existing methods.\n\n**Strengths:**\nThe paper's strengths lie in its novel formulation of dataset distillation as a mutual information maximization problem, providing a theoretical grounding to the task. The derivation of a numerically feasible lower bound and its optimization via contrastive learning is a significant contribution. The experimental results demonstrate the effectiveness of MIM4DD, showing consistent improvements over existing methods. The plug-and-play nature of the method is also a practical advantage.\n\n**Weaknesses:**\nThe paper does not adequately address the computational complexity and scalability of the MIM4DD method, particularly in comparison to existing dataset distillation techniques. The paper fails to address the potential for its contrastive learning framework to amplify existing biases present in the original dataset. The generalizability of MIM4DD beyond MNIST and CIFAR10 is questionable, as the paper does not discuss the sensitivity of the contrastive learning framework to the choice of data augmentations, which is crucial for adapting to datasets with different statistical properties. The performance of MIM4DD appears to be sensitive to both hyperparameter settings and architectural choices, although the paper's analysis has limitations. The paper exhibits a notable gap in its consideration of alternative information-theoretic approaches to dataset distillation.\n\n**Questions:**\n1. How does the computational complexity of MIM4DD scale with the size of the original dataset and the desired size of the distilled dataset, and what optimization techniques can be employed to mitigate this complexity?\n2. What are the potential biases or assumptions embedded in the mutual information maximization framework that could lead to suboptimal performance or unfair outcomes in specific contexts, and how can these biases be addressed?\n3. Are there alternative information-theoretic approaches to dataset distillation that the authors have not considered, and how might these alternatives offer advantages or disadvantages compared to MIM4DD?\n4. To what extent does the performance improvement of MIM4DD rely on specific hyperparameter settings or architectural choices, and how sensitive is the method to variations in these settings?\n5. What are the most significant limitations of the proposed MIM4DD method, and how might these limitations affect its applicability to more complex datasets or real-world scenarios?\n\n**Soundness:**\n3\n\n**Presentation:**\n3\n\n**Contribution:**\n3\n\n**Flag for Ethics Review:** NO\n\n**Rating:**\n6\n\n**Confidence:**\n3",
  "feedback_comments": [
    "The paper does not adequately address the computational complexity and scalability of the MIM4DD method, particularly in comparison to existing dataset distillation techniques. A theoretical analysis of the computational complexity is missing, and there are no empirical evaluations demonstrating the runtime and memory usage of MIM4DD compared to other dataset distillation methods on larger datasets or with higher-resolution images. The authors also fail to provide sufficient empirical results demonstrating the runtime and memory usage of MIM4DD and other dataset distillation methods across different datasets, including a breakdown of the time spent on different stages of the algorithm.",
    "The paper exhibits several critical oversights regarding potential biases and limitations within its mutual information maximization (MIM4DD) framework. First, while advocating for mutual information (MI) as a \"well-defined distributional metric,\" the paper neglects to discuss its limitations as the *sole* objective function, particularly in the context of imbalanced or biased datasets. Second, the paper fails to address the potential for its contrastive learning framework to amplify existing biases present in the original dataset. There is no analysis comparing the demographic or feature distributions of the synthetic and original datasets to identify potential biases. Third, the generalizability of MIM4DD beyond MNIST and CIFAR10 is questionable, as the paper does not discuss the sensitivity of the contrastive learning framework to the choice of data augmentations, which is crucial for adapting to datasets with different statistical properties. Finally, the paper does not adequately analyze the sensitivity of MIM4DD to hyperparameter choices or model architecture and how these choices might influence fairness or bias in the resulting distilled dataset.",
    "The paper exhibits a notable gap in its consideration of alternative information-theoretic approaches to dataset distillation. While the authors propose MIM4DD based on mutual information maximization, they fail to adequately explore and compare it with other potential methods. Specifically, the paper does not provide a detailed analysis of the computational cost associated with maximizing mutual information, nor does it explore alternative, potentially cheaper information-theoretic measures like Renyi entropy. Furthermore, the paper does not adequately address the potential limitations of using mutual information as the sole objective function, particularly in scenarios where preserving data characteristics beyond class separability is crucial. The paper also neglects to consider variational information bottleneck (VIB) principles, which could offer a different balance between compression and information preservation.",
    "The performance of MIM4DD appears to be sensitive to both hyperparameter settings and architectural choices, although the paper's analysis has limitations. The paper explores the impact of hyperparameters like $`\\beta`$ and $`\\lambda`$ in the MIM4DD loss, noting that increasing $`\\lambda`$ improves performance up to a threshold. Ablation studies also investigate the effect of different critic function architectures. However, the analysis is not fully comprehensive. For example, there is no explicit quantification of the performance impact of removing or modifying the contrastive learning component. Furthermore, the paper lacks a direct comparison of the computational cost of hyperparameter tuning for MIM4DD with that of other dataset distillation methods. A significant limitation is the lack of analysis of MIM4DD's performance with different network architectures like ResNet or VGG. The paper focuses on varying the critic function's architecture and hyperparameter tuning within the MIM4DD framework, but doesn't assess its generalizability across diverse model types."
  ]
}