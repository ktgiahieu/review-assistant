{
  "full_review": "**Summary:**\nThis paper introduces Binary Radiance Fields (BiRF), a novel radiance field representation that uses binary feature grids to achieve significant storage efficiency. The method employs a binarization-aware training scheme and a 2D-3D hybrid grid structure to encode local features with binary parameters (+1 or -1). The authors demonstrate that BiRF achieves competitive or superior performance compared to existing methods on standard datasets while requiring significantly less storage space.\n\n**Strengths:**\nThe primary strength of this paper is the significant reduction in storage space achieved by using binary radiance fields. The results demonstrate that high-fidelity view synthesis is possible with extremely compact models. The 2D-3D hybrid grid is a good design choice to balance fine details and global structure. The paper is well-written and easy to follow.\n\n**Weaknesses:**\nThe paper lacks a comprehensive evaluation of the limitations of using a binary representation for radiance fields, particularly in scenarios with complex lighting or material properties. The novelty of the 2D-3D hybrid grid is not clearly demonstrated through comprehensive quantitative comparisons. The analysis of the trade-offs between storage size and rendering quality is not thorough and lacks adequate justification in the context of existing radiance field compression techniques. The experimental results are unlikely to be reproducible due to a lack of sufficient detail in the description of the training and evaluation procedures.\n\n**Questions:**\n1. Can the authors provide a more detailed analysis of the limitations of BiRF in handling complex lighting effects, specular reflections, and transparent objects?\n2. How does the performance of BiRF scale to larger and more complex scenes compared to other grid-based radiance field representations?\n3. Can the authors provide a more detailed breakdown of the storage size components (grid, network weights, auxiliary data) for BiRF and the baselines?\n4. Can the authors provide more specific details regarding the training hyperparameters, such as learning rates for the network weights and feature grid, batch sizes, and optimizer settings?\n5. Can the authors provide the specific formulas or algorithms used to calculate PSNR and SSIM?\n6. Can the authors provide more details about the hardware and software environment used for training and evaluation, including the GPU model and versions of CUDA and PyTorch?\n\n**Soundness:**\n3 good\n\n**Presentation:**\n3 good\n\n**Contribution:**\n3 good\n\n**Rating:**\n6 marginally above the acceptance threshold\n\n**Confidence:**\n3 You are fairly confident in your assessment.",
  "feedback_comments": [
    "The paper lacks a comprehensive evaluation of the limitations of using a binary representation for radiance fields, particularly in scenarios with complex lighting or material properties. While the paper claims superior performance and increased visual fidelity with minimal storage space (Section: Ablation Study > Take-Away > Dynamic scene reconstruction, Paragraph: 2), it fails to provide sufficient quantitative evidence to support these claims, especially concerning the representation of high-frequency details. There is a lack of direct quantitative analysis using metrics like SSIM or LPIPS, specifically focusing on regions with high-frequency details.",
    "The paper attempts to address information loss due to binarization primarily through 'binarization-aware training' and the use of a 'distortion loss' (Section: Abstract > Radiance Fields Compression, Paragraph: 2, 3). A sparsity loss is also employed to improve efficiency (Section: Loss > Sparsity loss, Paragraph: 1, 2). However, the paper falls short in several key areas. First, it lacks a theoretical analysis or empirical evidence quantifying the information loss during binarization.",
    "The paper claims novelty in addressing the storage limitations of explicit grid structures like Plenoxels, TensoRF, and Instant-NGP using a 2D-3D hybrid grid. However, the novelty is not clearly demonstrated through comprehensive quantitative comparisons. While the paper compares against compressed TensoRF-VM models (\"Ours-B4 model has superior reconstruction quality only with 2.8 MB of storage capacity, which is smaller than the compressed TensoRF-VM models.\"), it lacks direct comparisons of memory usage, rendering time, and memory access patterns against the original Plenoxels, TensoRF, and Instant-NGP on a standardized set of scenes.",
    "The paper's analysis of the trade-offs between storage size and rendering quality is not thorough and lacks adequate justification in the context of existing radiance field compression techniques. While the paper presents quantitative comparisons of BiRF's storage size and rendering quality (PSNR) against other techniques, it lacks a detailed breakdown of storage size components (grid, network weights, auxiliary data) for BiRF and baselines across all datasets. The absence of confidence intervals or standard deviations for PSNR/SSIM values makes it impossible to determine the statistical significance of BiRF's performance.",
    "The paper's experimental results are unlikely to be reproducible due to a lack of sufficient detail in the description of the training and evaluation procedures. The paper fails to explicitly state the specific hyperparameter values used during training, such as learning rates, batch sizes, and optimizer settings (\"The provided context does not explicitly specify the learning rates for the network weights and the feature grid separately, nor does it provide their respective values.\")."
  ]
}