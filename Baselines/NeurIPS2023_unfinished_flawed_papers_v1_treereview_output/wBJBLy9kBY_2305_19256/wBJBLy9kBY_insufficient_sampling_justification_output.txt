{
  "full_review": "**Summary:**\nThis paper introduces Ambient Diffusion, a novel framework for training diffusion models on corrupted data. The core idea is to approximate the Tweedie integral with a more manageable surrogate and to introduce a lightweight deterministic correction term to refine the samples. The method is evaluated on image generation and inverse problems, demonstrating competitive performance compared to existing diffusion models, even when those models are trained on clean data. The paper also explores the memorization properties of the proposed approach.\n\n**Strengths:**\nThe paper presents a simple and effective approach to training diffusion models on corrupted data, a setting with practical relevance. The results demonstrate that high-quality generative models can be learned even with significant data corruption. The method shows promise in mitigating memorization issues in generative models. The paper provides theoretical justification for the proposed training objective. The experiments demonstrate strong performance on image generation and inverse problems, often outperforming existing methods in terms of speed and quality. The open-source code and models enhance reproducibility and facilitate further research.\n\n**Weaknesses:**\nThe paper lacks a comprehensive analysis of the computational costs associated with the surrogate approximation, especially concerning how this cost scales with increasing data dimensionality or corruption levels. The paper's analysis of failure modes is incomplete, particularly regarding non-Gaussian noise distributions and the potential for bias amplification. The justification for the specific choice of surrogate is primarily based on convenience and empirical performance, without a thorough comparison to other potential surrogates or a detailed discussion of its limitations. The paper provides insufficient detail and justification for the 'lightweight deterministic correction' (Eq. 3.4), and how this correction interacts with the core mean substitution approach.\n\n**Questions:**\n1. How does the computational cost of the surrogate approximation scale with increasing data dimensionality and corruption levels compared to the original Tweedie integral?\n2. What are the specific failure modes of Ambient Diffusion, particularly with non-Gaussian noise distributions, and how can these be mitigated?\n3. Can you provide a more detailed theoretical justification for why the chosen surrogate is a suitable approximation of the Tweedie integral, and how does its performance compare to other potential surrogates?\n4. What is the computational cost of the lightweight deterministic correction, and how does it contribute to the overall performance of Ambient Diffusion?\n5. How does the choice of the corruption operator 'A' affect the performance of Ambient Diffusion, and what are the guidelines for selecting an appropriate 'A' for different types of data and corruption scenarios?\n6. Does the method disproportionately affect certain features or subgroups within the datasets, potentially exacerbating existing biases?\n\n**Soundness:**\n3 good\n\n**Presentation:**\n3 good\n\n**Contribution:**\n3 good\n\n**Rating:**\n7 accept, but needs minor improvements\n\n**Confidence:**\n4 You are confident in your assessment, but not absolutely certain.",
  "feedback_comments": [
    "The paper lacks a comprehensive discussion of the computational cost associated with the surrogate approximation compared to the original Tweedie integral, especially concerning how this cost scales with increasing data dimensionality or corruption levels. The paper mentions training time on an A100 GPU (Section: Reduction > Finetuning Deepfloyd’s IF., Paragraph: 5) but fails to provide a detailed analysis of computational complexity.",
    "The paper's analysis of failure modes is incomplete. While it explores sensitivity to corruption magnitude (Section: Reduction > Finetuning Deepfloyd’s IF., Paragraph: 4), it doesn't adequately address the limitations related to non-Gaussian noise distributions or how architectural choices might amplify failure modes. The paper describes two corruption processes (Inpainting and Gaussian measurements) but doesn't identify which types are most likely to cause failure or explain why.",
    "While the paper analyzes the sensitivity to the choice of the corruption operator 'A' through empirical evaluations and provides examples of 'A' for inpainting and Gaussian measurements (Section: Sampling, Paragraph: 9-10), it lacks a theoretical justification for why the surrogate \\(\\mathbb E[\\mathbf x_0\\mid A\\,\\mathbf x_t, A]\\) is a suitable approximation of the intractable Tweedie integral \\(\\mathbb E[\\mathbf x_0\\mid \\mathbf x_t]\\) for various 'A'.",
    "Although the paper acknowledges performance degradation under severe corruption, as evidenced by FID and Inception Scores (Section: Training from scratch on corrupted data, Paragraph: 9), it does not provide a detailed analysis of *why* the performance degrades or *how* the approximation fails under these conditions. The claim of stability in practice (\"in thousands of runs we have never observed divergence\" (Section: Sampling, Paragraph: 3)) is not sufficiently supported by a rigorous analysis of failure modes.",
    "The paper justifies its choice of surrogate \\(\\mathbb E[\\mathbf x_0\\mid A\\,\\mathbf x_t, A]\\) for the Tweedie integral based on convenience and state-of-the-art performance (Abstract, Paragraph 1; Sampling, Paragraph 6). However, it does not provide a direct theoretical or empirical comparison of its chosen surrogate with other potential surrogates, nor does it discuss the specific theoretical properties or computational trade-offs that might make other surrogates unsuitable.",
    "While the paper acknowledges the importance of the corruption operator \\(A\\) (Sampling, Paragraph 6) and mentions a trade-off between generator quality and corruption levels (Section: Finetuning foundation models on corrupted data > Memorization., Paragraph: 7), it lacks a comprehensive discussion of the limitations of the chosen surrogate, particularly regarding biases in the deterministic correction term and specific scenarios where it might underperform.",
    "The paper also lacks a comprehensive discussion of the computational complexity of the chosen surrogate compared to alternatives (Sub-question 4) and does not provide empirical evidence (e.g., runtime measurements, memory profiling) comparing the computational cost of their surrogate with that of other Tweedie integral approximations, particularly in the context of varying image resolutions and dataset sizes (Sub-question 6).",
    "The paper does not adequately analyze whether the chosen corruption method disproportionately affects certain features or subgroups within the datasets, potentially exacerbating existing biases. Critically, the paper fails to address the potential for the model to amplify pre-existing biases in the original data (Section: Finetuning foundation models on corrupted data > Memorization., Paragraph: 2).",
    "While the paper acknowledges the sensitivity of the deterministic correction term to hyperparameters and corruption levels, it lacks a comprehensive analysis of its performance under different *types* of corruption, adversarial examples, or out-of-distribution data. This limited analysis of bias amplification and the robustness of the correction term represents a significant gap in the paper's evaluation.",
    "The paper's articulation of computational costs and resource requirements for Ambient Diffusion is incomplete and lacks rigorous comparison to alternative methods. While the paper claims state-of-the-art sampling speed (Abstract, Paragraph 1), it fails to provide sufficient evidence to support this claim through detailed computational analysis.",
    "The paper does not explicitly quantify the computational resources (e.g., memory, FLOPs) required for training Ambient Diffusion from scratch, nor does it provide a direct comparison to the computational costs of training standard diffusion models (Sub-question 1).",
    "The paper also does not thoroughly benchmark the inference costs of Ambient Diffusion against other state-of-the-art generative models across different image resolutions and dataset complexities (Sub-question 2).",
    "The limited details regarding hardware and software configurations (Sub-question 3), such as the omission of CPU, memory, storage, and specific software versions, hinder the reproducibility of the reported performance.",
    "The paper lacks a comprehensive analysis of the computational cost associated with key components like the Tweedie integral approximation and the deterministic correction step as model complexity increases (Sub-question 4).",
    "The paper also does not provide a detailed breakdown of computational costs (FLOPs, memory usage) for each stage of the Ambient Diffusion process, nor a direct comparison with methods like DDPM, DDIM, and GANs (Sub-question 5).",
    "The paper provides insufficient detail and justification for the 'lightweight deterministic correction' (Eq. 3.4). A critical deficiency is the lack of quantitative analysis of its computational cost (FLOPs, memory usage, runtime), making it impossible to assess its efficiency relative to the computational savings from the surrogate Tweedie integral approximation (Section: Training from scratch on corrupted data, Paragraph: 6).",
    "The paper lacks sufficient detail regarding the architectural choices and hyperparameters critical for the correction's effectiveness. It fails to specify the architectural components used or provide a rationale for the hyperparameter values chosen. There is no sensitivity analysis demonstrating the impact of varying these parameters on performance.",
    "The paper does not quantify the individual contribution of the correction, explore varying its strength or functional form, or assess its impact on performance metrics like FID and IS across different datasets and corruption levels. The absence of such analysis makes it difficult to isolate the effect of the correction and understand its true value."
  ]
}