{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af3125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from keys import (\n",
    "    KEY1,\n",
    "    LOCATION,\n",
    "    API_VERSION,\n",
    "    ENDPOINT,\n",
    "    DEPLOYMENT_GPT_o3_MINI\n",
    ")\n",
    "from llm_client import LLMClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67463b77",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e533fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(alist):\n",
    "    if \".DS_Store\" in alist:\n",
    "        alist.remove(\".DS_Store\")\n",
    "    return alist\n",
    "\n",
    "def save_flaws(flaws_file, flaws_list, flaws_dir):\n",
    "    file_path = os.path.join(flaws_dir, flaws_file)\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(flaws_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def load_review_files(reviews_dir):\n",
    "    paper_reviews = clean_list(os.listdir(reviews_dir))\n",
    "    return paper_reviews\n",
    "\n",
    "def load_review(reviews_dir, review_file):\n",
    "    file_path = os.path.join(reviews_dir, review_file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afdca2",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf5676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert academic reviewer with extensive experience in synthesizing peer reviews and rebuttals for top-tier machine learning conferences like ICLR. Given multiple peer reviews of an academic paper, along with the corresponding author rebuttals and reviewer replies, your task is to extract a **consensus list of actionable flaws or improvement points**.\n",
    "\n",
    "Please follow these guidelines:\n",
    "1. Identify flaws, limitations, or suggestions for improvement raised by reviewers.\n",
    "2. Prioritize those where **authors acknowledge** the issue — either by:\n",
    "   - Agreeing with the flaw and planning to address it in future work or a camera-ready version.\n",
    "   - Acknowledging the issue but providing a reason for not addressing it now (e.g., limited time, compute, or out-of-scope).\n",
    "3. Ignore points of disagreement or unclear consensus between reviewers and authors.\n",
    "\n",
    "Your output should be a **python list of actionable items**, each:\n",
    "- Clear, specific, and concise.\n",
    "- Based on mutual understanding between reviewers and authors.\n",
    "- Reflecting consensus, even if the change won't be implemented immediately.\n",
    "\n",
    "\n",
    "Now analyze the following reviews and rebuttals:\\n\\n\\n\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe4a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_flaws_from_llm(prompt, reviews_list):\n",
    "    combined_review = \"\"\n",
    "    for i, review in enumerate(reviews_list):\n",
    "        combined_review += f\"{'-'*50}\\nReview {i+1}\\n{'-'*50}\\n{review}\\n\\n\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert academic reviewer with extensive experience in synthesizing peer reviews and rebuttals for top-tier machine learning conferences like ICLR. Your goal is to extract a consensus list of actionable improvements agreed upon by both reviewers and authors.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt + combined_review}\n",
    "    ]\n",
    "\n",
    "    llm_c = LLMClient(\n",
    "        api_key=KEY1,\n",
    "        api_version=API_VERSION,\n",
    "        endpoint=ENDPOINT,\n",
    "        deployment=DEPLOYMENT_GPT_o3_MINI\n",
    "    )\n",
    "    llm_resp = llm_c.get_llm_response(messages=messages)\n",
    "    return llm_resp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1809cb31",
   "metadata": {},
   "source": [
    "### Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab8ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_flaws(review_files, reviews_dir, flaws_dir):\n",
    "    for review_file in review_files:\n",
    "        try:\n",
    "            review = load_review(reviews_dir, review_file)\n",
    "            flaws = get_flaws_from_llm(prompt, review)\n",
    "            if flaws:\n",
    "                print(flaws)\n",
    "                # save_flaws(review_file, flaws, flaws_dir)\n",
    "            else:\n",
    "                raise ValueError(f\"[-] Failed to process: {review_file}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        break  # remove break if you want to process multiple papers. For testing using break to break the loop after one paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_review_files = load_review_files(\"ICLR2024_Reviews_Raw/accepted\")\n",
    "rejected_review_files = load_review_files(\"ICLR2024_Reviews_Raw/rejected\")\n",
    "\n",
    "# Uncomment these two lines when everything is ready and you want to run the whole notebbok to generate flaws for all papers\n",
    "# generate_flaws(accepted_review_files, \"ICLR2024_Reviews_Processed/accepted\", \"ICLR2024_Reviews_Flaws/accepted\")\n",
    "# generate_flaws(rejected_review_files, \"ICLR2024_Reviews_Processed/rejected\", \"ICLR2024_Reviews_Flaws/rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b928cf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"Reword the opening abstract and introduction to more accurately describe related work and clarify that while there is existing literature on causality (including in dynamic settings), the specific challenges of dynamical causal discovery have not been sufficiently addressed.\",\n",
      "    \"Improve the clarity of key definitions and technical language—e.g. explain terms like 'filtered probability space', 'sticky value', and the precise conditions (e.g., smoothness and limit existence) underlying the formal statements—and add appropriate textbook or literature references (including for process‐based causality axioms and counterfactual frameworks).\",\n",
      "    \"Revise grammatical phrasing and sentence structure throughout the paper (including examples such as the counterfactual statement on cause and effect) to improve readability and reduce potential ambiguities.\",\n",
      "    \"Clarify and update notation inconsistencies, including the explicit dependency of state evolution on actions (e.g. in X(t) and u) and the notation for value functions (e.g. ensuring that V^π properly reflects dependence on the policy), as well as defining acronyms like 'HP' (Halpern and Pearl) at first use.\",\n",
      "    \"Enhance figure captions and experimental descriptions by providing clear explanations of axes, color codes, panels, and the rationale behind the experimental set‐ups; include detailed clarifications in the appendix where possible and note plans to release complete reproducible code.\",\n",
      "    \"Modify the paper’s structure or add guiding commentary so that the motivation for critiquing existing causal frameworks is better tied to the experimental examples—explaining early on why current methods (e.g. SCMs with interventions) are limited in high-dimensional or pixel-level settings and how the RL-based estimation of 'grit' and 'reachability' addresses these issues.\",\n",
      "    \"Expand the literature review to acknowledge and briefly compare related work in reverse causality (e.g. citing Gelman and Imbens, 2013) to better situate the proposed approach within the broader context of causal inference.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "generate_flaws(accepted_review_files, \"ICLR2024_Reviews_Processed/accepted\", \"ICLR2024_Reviews_Flaws/accepted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea564afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reviewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
