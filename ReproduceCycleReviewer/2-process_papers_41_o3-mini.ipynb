{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6da4900",
   "metadata": {},
   "source": [
    "# Process 300 papers using GPT 4o and 4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219bcb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from keys import (\n",
    "    DEPLOYMENT_GPT_o3_MINI,\n",
    "    DEPLOYMENT_GPT_41,\n",
    "    API_VERSION,\n",
    "    ENDPOINT,\n",
    "    KEY1\n",
    ")\n",
    "\n",
    "from llm_client import LLMClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930348c",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1014489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_100_sampled_papers():\n",
    "\n",
    "    with open('100_sampled_paper_ids.txt', 'r') as file:\n",
    "        paper_ids = file.read().splitlines()\n",
    "\n",
    "    # Add .json to each paper ID\n",
    "    json_filenames = [paper_id + '.json' for paper_id in paper_ids]\n",
    "\n",
    "    return json_filenames\n",
    "\n",
    "def load_already_processed_papers(deployment):\n",
    "    processed_path = os.path.join(\"LLM_Responses\", deployment)\n",
    "    processed_papers = os.listdir(processed_path)\n",
    "    if \".DS_Store\" in processed_papers:\n",
    "        processed_papers.remove(\".DS_Store\")\n",
    "    return processed_papers\n",
    "\n",
    "def load_paper(paper_json):\n",
    "    json_path = os.path.join(\"review-5k-dataset\", \"300\", paper_json)\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f) \n",
    "    return data\n",
    "\n",
    "def save_llm_response(response_file, deployment, llm_response):\n",
    "    txt_path = os.path.join(\"LLM_Responses\", deployment, response_file)\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad81ec55",
   "metadata": {},
   "source": [
    "# Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af721cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_papers(deployment, sampled_papers):\n",
    "    already_processed = load_already_processed_papers(deployment)\n",
    "\n",
    "    for i, paper in enumerate(sampled_papers):\n",
    "        paper_dict = load_paper(paper)\n",
    "        messages = paper_dict[\"messages\"]\n",
    "        for msg in messages:\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                messages.remove(msg)\n",
    "            if msg[\"role\"] == \"system\":\n",
    "                msg[\"role\"] = \"user\"\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"You are required to generate **4** reviews for this paper, following the instructions given above. Make sure that all the reviews are separated by a visible indicator.\"\n",
    "        })\n",
    "        paper_id = paper_dict[\"id\"]\n",
    "        paper_txt = f\"{paper_id}.txt\"\n",
    "        if paper_txt in already_processed:\n",
    "            continue\n",
    "        else:\n",
    "            llm_c = LLMClient(\n",
    "                api_key=KEY1,\n",
    "                api_version=API_VERSION,\n",
    "                endpoint=ENDPOINT,\n",
    "                deployment=deployment\n",
    "            )\n",
    "            llm_resp = llm_c.get_llm_response(messages=messages)\n",
    "            if llm_resp:\n",
    "                save_llm_response(paper_txt, deployment, llm_resp)\n",
    "            else:\n",
    "                print(f\"[-] Failed to process: {paper_txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432d1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_100 = get_100_sampled_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_papers(deployment=DEPLOYMENT_GPT_o3_MINI, sampled_papers=sampled_100)\n",
    "process_papers(deployment=DEPLOYMENT_GPT_41, sampled_papers=sampled_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304298e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reviewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
